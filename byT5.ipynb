{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91f681354fca462a9412fa1e41f08b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_22eb0620c5f44864897956f4de51dc15",
              "IPY_MODEL_6726f2ff3b054878a0961c509ee1c9b1",
              "IPY_MODEL_f7cc41e6f40548a4a78dfb1330ed30c9"
            ],
            "layout": "IPY_MODEL_455e831c9272465e9c87ed474a255f8d"
          }
        },
        "22eb0620c5f44864897956f4de51dc15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a76e75d1e9a34801a2e8677c1c3ecb46",
            "placeholder": "​",
            "style": "IPY_MODEL_8ec5cf1502b84c639c85554a8148792e",
            "value": "100%"
          }
        },
        "6726f2ff3b054878a0961c509ee1c9b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a29200f076e451584befd369ae2a18c",
            "max": 18,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_69c635ac751a416fa4a795647a48cd0f",
            "value": 18
          }
        },
        "f7cc41e6f40548a4a78dfb1330ed30c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1caf91d29264b42b77756a003a97856",
            "placeholder": "​",
            "style": "IPY_MODEL_03afb6be1c424dc29d216bd5a8209da8",
            "value": " 18/18 [00:05&lt;00:00,  3.01ba/s]"
          }
        },
        "455e831c9272465e9c87ed474a255f8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a76e75d1e9a34801a2e8677c1c3ecb46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec5cf1502b84c639c85554a8148792e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a29200f076e451584befd369ae2a18c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c635ac751a416fa4a795647a48cd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1caf91d29264b42b77756a003a97856": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03afb6be1c424dc29d216bd5a8209da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets evaluate sacrebleu"
      ],
      "metadata": {
        "id": "Mfxdqv810FvL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8MvY-mPWENS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da97e35c-22d2-498a-9e76-e784a9de4e74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-09 14:17:54--  https://pmb.let.rug.nl/releases/pmb-4.0.0.zip\n",
            "Resolving pmb.let.rug.nl (pmb.let.rug.nl)... 129.125.55.158\n",
            "Connecting to pmb.let.rug.nl (pmb.let.rug.nl)|129.125.55.158|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3005186356 (2.8G) [application/zip]\n",
            "Saving to: ‘pmb-4.0.0.zip’\n",
            "\n",
            "pmb-4.0.0.zip        54%[=========>          ]   1.52G  12.7MB/s    eta 95s    "
          ]
        }
      ],
      "source": [
        "!wget https://pmb.let.rug.nl/releases/pmb-4.0.0.zip\n",
        "!unzip -q \"pmb-4.0.0.zip\" \"*/gold/*\" -d .\n",
        "!unzip -q \"pmb-4.0.0.zip\" \"*/silver/*\" -d ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/huggingface/transformers/blob/main/examples/pytorch/translation/run_translation.py"
      ],
      "metadata": {
        "id": "f--Ro0Ni1f-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "metadata": {
        "id": "_ZcYagW74y5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "space_re = re.compile('\\s+')\n",
        "\n",
        "data_dir = os.path.join('pmb-4.0.0', 'data')\n",
        "data = []\n",
        "\n",
        "for lang in os.listdir(data_dir):\n",
        "  for quality in ['gold', 'silver']:\n",
        "    quality_folder = os.path.join(data_dir, lang, quality)\n",
        "\n",
        "    for upper_filedir in os.listdir(quality_folder):\n",
        "      filedirs = os.path.join(quality_folder, upper_filedir)\n",
        "\n",
        "      for filedir in os.listdir(filedirs):\n",
        "        file_folder = os.path.join(filedirs, filedir)\n",
        "\n",
        "        with open(os.path.join(file_folder, f'{lang}.status')) as f:\n",
        "          if 'bronze' in f.read().lower():\n",
        "            continue\n",
        "\n",
        "        with open(os.path.join(file_folder, f'{lang}.raw')) as f:\n",
        "          raw_text = f.read().strip()\n",
        "        \n",
        "        with open(os.path.join(file_folder, f'{lang}.drs.sbn')) as f:\n",
        "          raw_drs = f.read().strip()\n",
        "          drs = '\\n'.join(\n",
        "              space_re.sub(' ', line) \n",
        "              for line in raw_drs.split('\\n') \n",
        "              if not line.startswith('%%%')\n",
        "          )\n",
        "\n",
        "        data.append({\n",
        "            'lang': lang, \n",
        "            'quality': quality, \n",
        "            'text': raw_text, \n",
        "            'drs': drs\n",
        "        })"
      ],
      "metadata": {
        "id": "MeWig_vJvh68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = defaultdict(lambda: defaultdict(int))\n",
        "for info in data:\n",
        "  stats[info['lang']][info['quality']] += 1\n",
        "\n",
        "for l, qualities in stats.items():\n",
        "  for q, qnum in qualities.items():\n",
        "    print(l, q, qnum)"
      ],
      "metadata": {
        "id": "cTvA9VOmx37D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0920cb8-bec2-49ea-c22a-0fb87db0a7e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nl gold 1467\n",
            "nl silver 3\n",
            "de gold 2844\n",
            "de silver 16\n",
            "en gold 10715\n",
            "en silver 428\n",
            "it gold 1686\n",
            "it silver 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    T5ForConditionalGeneration, AutoTokenizer,\n",
        "    DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, \n",
        "    Seq2SeqTrainer\n",
        ")"
      ],
      "metadata": {
        "id": "SB1SEL1s3jXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained(\"google/byt5-small\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/byt5-small\")"
      ],
      "metadata": {
        "id": "wqCq4ulGzrhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "ds = Dataset.from_list(data)\n",
        "ds"
      ],
      "metadata": {
        "id": "LU94xdOq1zO5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15e87146-1646-4649-f63d-e606bc697b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['lang', 'quality', 'text', 'drs'],\n",
              "    num_rows: 17168\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 512\n",
        "\n",
        "def process(examples):\n",
        "  model_inputs = tokenizer(examples['text'], max_length=max_len, truncation=True)\n",
        "  labels = tokenizer(examples['drs'], max_length=max_len, truncation=True)\n",
        "  model_inputs['labels'] = labels['input_ids']\n",
        "  return model_inputs\n",
        "\n",
        "ds = ds.map(process, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "91f681354fca462a9412fa1e41f08b96",
            "22eb0620c5f44864897956f4de51dc15",
            "6726f2ff3b054878a0961c509ee1c9b1",
            "f7cc41e6f40548a4a78dfb1330ed30c9",
            "455e831c9272465e9c87ed474a255f8d",
            "a76e75d1e9a34801a2e8677c1c3ecb46",
            "8ec5cf1502b84c639c85554a8148792e",
            "5a29200f076e451584befd369ae2a18c",
            "69c635ac751a416fa4a795647a48cd0f",
            "e1caf91d29264b42b77756a003a97856",
            "03afb6be1c424dc29d216bd5a8209da8"
          ]
        },
        "id": "kQoEQXHA0Rpa",
        "outputId": "fdbbd129-1943-424a-f08c-aa11d5bc692c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/18 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "91f681354fca462a9412fa1e41f08b96"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.train_test_split(test_size=0.1, seed=SEED)"
      ],
      "metadata": {
        "id": "ifSowgTy4rut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"chrf\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"chrf\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "kHLB1c2R-hkh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_pad_token_id = -100\n",
        "data_collator = DataCollatorForSeq2Seq(\n",
        "    tokenizer,\n",
        "    model=model,\n",
        "    label_pad_token_id=label_pad_token_id\n",
        ")"
      ],
      "metadata": {
        "id": "3Uc5sMB2oIeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir='results',\n",
        "    report_to='none',\n",
        "    evaluation_strategy='epoch',\n",
        "    # eval_steps=1000,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    save_strategy='epoch',\n",
        "    save_total_limit=3,\n",
        "    predict_with_generate=True,\n",
        "    generation_max_length=max_len,\n",
        "    generation_num_beams=3,\n",
        ")\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "  model=model,\n",
        "  args=training_args,\n",
        "  train_dataset=ds['train'],\n",
        "  eval_dataset=ds['test'],\n",
        "  tokenizer=tokenizer,\n",
        "  data_collator=data_collator,\n",
        "  compute_metrics=compute_metrics\n",
        "  # callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
        ")"
      ],
      "metadata": {
        "id": "ofI3Fwqn0Ql7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "efX8RZzu5KBq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "641e2b36-2264-4223-cec0-a0a4b2608355"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the training set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: drs, lang, quality, text. If drs, lang, quality, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 15451\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 4\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 11589\n",
            "  Number of trainable parameters = 299637760\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11590' max='11589' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11589/11589 1:57:40, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Chrf</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.260400</td>\n",
              "      <td>0.173349</td>\n",
              "      <td>66.800100</td>\n",
              "      <td>180.828800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.198900</td>\n",
              "      <td>0.135261</td>\n",
              "      <td>72.739100</td>\n",
              "      <td>179.987200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='170' max='430' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [170/430 07:23 < 11:23, 0.38 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: drs, lang, quality, text. If drs, lang, quality, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1717\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to results/checkpoint-3863\n",
            "Configuration saved in results/checkpoint-3863/config.json\n",
            "Model weights saved in results/checkpoint-3863/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-3863/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-3863/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: drs, lang, quality, text. If drs, lang, quality, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1717\n",
            "  Batch size = 4\n",
            "Saving model checkpoint to results/checkpoint-7726\n",
            "Configuration saved in results/checkpoint-7726/config.json\n",
            "Model weights saved in results/checkpoint-7726/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-7726/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-7726/special_tokens_map.json\n",
            "The following columns in the evaluation set don't have a corresponding argument in `T5ForConditionalGeneration.forward` and have been ignored: drs, lang, quality, text. If drs, lang, quality, text are not expected by `T5ForConditionalGeneration.forward`,  you can safely ignore this message.\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1717\n",
            "  Batch size = 4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11589' max='11589' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11589/11589 2:19:56, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Chrf</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.260400</td>\n",
              "      <td>0.173349</td>\n",
              "      <td>66.800100</td>\n",
              "      <td>180.828800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.198900</td>\n",
              "      <td>0.135261</td>\n",
              "      <td>72.739100</td>\n",
              "      <td>179.987200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.180800</td>\n",
              "      <td>0.125466</td>\n",
              "      <td>74.754000</td>\n",
              "      <td>177.947000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to results/checkpoint-11589\n",
            "Configuration saved in results/checkpoint-11589/config.json\n",
            "Model weights saved in results/checkpoint-11589/pytorch_model.bin\n",
            "tokenizer config file saved in results/checkpoint-11589/tokenizer_config.json\n",
            "Special tokens file saved in results/checkpoint-11589/special_tokens_map.json\n",
            "Deleting older checkpoint [results/checkpoint-3648] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=11589, training_loss=0.27546285358863126, metrics={'train_runtime': 8397.3769, 'train_samples_per_second': 5.52, 'train_steps_per_second': 1.38, 'total_flos': 3499509961884672.0, 'train_loss': 0.27546285358863126, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_example = ds['test'][16]\n",
        "print(test_example['text'])\n",
        "print(test_example['drs'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h4QG_fr0m9w",
        "outputId": "ef74fc1e-f2d7-4cbe-baf3-fcdea0e04a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My father's in the garden.\n",
            "person.n.01 Role +1 % My father [0-9]\n",
            "father.n.01 Of speaker % \n",
            "be.v.03 Theme -2 Time +1 Location +2 % 's in [9-14]\n",
            "time.n.08 EQU now % \n",
            "garden.n.03 % the garden. [15-26]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model.generate(\n",
        "    torch.tensor([test_example['input_ids']]).cuda(), \n",
        "    max_new_tokens=512,\n",
        "    num_beams=3\n",
        ")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "_WRCsAwb5iha",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9231fa90-7ece-415a-b4aa-a78329740eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "person.n.01 Role +1 % My father [0-8]\n",
            "father.n.01 Of speaker % \n",
            "be.v.03 Theme -2 Time +1 Location +2 %'s in [9-13]\n",
            "time.n.08 EQU now % \n",
            "garden.n.01 % the garden. [14-23]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, i in enumerate(ds['train']):\n",
        "  if 'Yamamoto' in i['text']:\n",
        "    print(idx, i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycwcHHOlz2J2",
        "outputId": "812b46e8-7fbe-4cfd-d2a9-664fd70ceb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2814 {'lang': 'en', 'quality': 'gold', 'text': 'Ms. Yamamoto teaches us English.', 'drs': 'ms.n.05 % Ms. [0-3]\\nfemale.n.02 Name \"Yamamoto\" Title -1 % Yamamoto [4-12]\\nteach.v.01 Agent -1 Time +1 Recipient +2 Theme +3 % teaches [13-20]\\ntime.n.08 EQU now % \\nperson.n.01 EQU speaker % us [21-23]\\nenglish.n.01 % English. [24-32]', 'input_ids': [80, 118, 49, 35, 92, 100, 112, 100, 112, 114, 119, 114, 35, 119, 104, 100, 102, 107, 104, 118, 35, 120, 118, 35, 72, 113, 106, 111, 108, 118, 107, 49, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [112, 118, 49, 113, 49, 51, 56, 35, 40, 35, 80, 118, 49, 35, 94, 51, 48, 54, 96, 13, 105, 104, 112, 100, 111, 104, 49, 113, 49, 51, 53, 35, 81, 100, 112, 104, 35, 37, 92, 100, 112, 100, 112, 114, 119, 114, 37, 35, 87, 108, 119, 111, 104, 35, 48, 52, 35, 40, 35, 92, 100, 112, 100, 112, 114, 119, 114, 35, 94, 55, 48, 52, 53, 96, 13, 119, 104, 100, 102, 107, 49, 121, 49, 51, 52, 35, 68, 106, 104, 113, 119, 35, 48, 52, 35, 87, 108, 112, 104, 35, 46, 52, 35, 85, 104, 102, 108, 115, 108, 104, 113, 119, 35, 46, 53, 35, 87, 107, 104, 112, 104, 35, 46, 54, 35, 40, 35, 119, 104, 100, 102, 107, 104, 118, 35, 94, 52, 54, 48, 53, 51, 96, 13, 119, 108, 112, 104, 49, 113, 49, 51, 59, 35, 72, 84, 88, 35, 113, 114, 122, 35, 40, 35, 13, 115, 104, 117, 118, 114, 113, 49, 113, 49, 51, 52, 35, 72, 84, 88, 35, 118, 115, 104, 100, 110, 104, 117, 35, 40, 35, 120, 118, 35, 94, 53, 52, 48, 53, 54, 96, 13, 104, 113, 106, 111, 108, 118, 107, 49, 113, 49, 51, 52, 35, 40, 35, 72, 113, 106, 111, 108, 118, 107, 49, 35, 94, 53, 55, 48, 54, 53, 96, 1]}\n",
            "4445 {'lang': 'it', 'quality': 'gold', 'text': 'Yamamoto aveva centosessantadue navi.', 'drs': 'male.n.02 Name \"Yamamoto\" % Yamamoto [0-8]\\nhave.v.01 Pivot -1 Time +1 Theme +2 % aveva centosessantadue [9-31]\\ntime.n.08 TPR now % \\nship.n.01 Quantity 162 % navi. [32-37]', 'input_ids': [92, 100, 112, 100, 112, 114, 119, 114, 35, 100, 121, 104, 121, 100, 35, 102, 104, 113, 119, 114, 118, 104, 118, 118, 100, 113, 119, 100, 103, 120, 104, 35, 113, 100, 121, 108, 49, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [112, 100, 111, 104, 49, 113, 49, 51, 53, 35, 81, 100, 112, 104, 35, 37, 92, 100, 112, 100, 112, 114, 119, 114, 37, 35, 40, 35, 92, 100, 112, 100, 112, 114, 119, 114, 35, 94, 51, 48, 59, 96, 13, 107, 100, 121, 104, 49, 121, 49, 51, 52, 35, 83, 108, 121, 114, 119, 35, 48, 52, 35, 87, 108, 112, 104, 35, 46, 52, 35, 87, 107, 104, 112, 104, 35, 46, 53, 35, 40, 35, 100, 121, 104, 121, 100, 35, 102, 104, 113, 119, 114, 118, 104, 118, 118, 100, 113, 119, 100, 103, 120, 104, 35, 94, 60, 48, 54, 52, 96, 13, 119, 108, 112, 104, 49, 113, 49, 51, 59, 35, 87, 83, 85, 35, 113, 114, 122, 35, 40, 35, 13, 118, 107, 108, 115, 49, 113, 49, 51, 52, 35, 84, 120, 100, 113, 119, 108, 119, 124, 35, 52, 57, 53, 35, 40, 35, 113, 100, 121, 108, 49, 35, 94, 54, 53, 48, 54, 58, 96, 1]}\n",
            "13475 {'lang': 'en', 'quality': 'gold', 'text': 'Yamamoto is also a friend of mine.', 'drs': 'male.n.02 Name \"Yamamoto\" % Yamamoto [0-8]\\nbe.v.01 Theme -1 Time +1 Co-Theme +2 % is also [9-16]\\ntime.n.08 EQU now % \\nperson.n.01 Role +1 % a friend of [17-28]\\nfriend.n.01 Of +1 % \\nperson.n.01 EQU speaker % mine. [29-34]', 'input_ids': [92, 100, 112, 100, 112, 114, 119, 114, 35, 108, 118, 35, 100, 111, 118, 114, 35, 100, 35, 105, 117, 108, 104, 113, 103, 35, 114, 105, 35, 112, 108, 113, 104, 49, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [112, 100, 111, 104, 49, 113, 49, 51, 53, 35, 81, 100, 112, 104, 35, 37, 92, 100, 112, 100, 112, 114, 119, 114, 37, 35, 40, 35, 92, 100, 112, 100, 112, 114, 119, 114, 35, 94, 51, 48, 59, 96, 13, 101, 104, 49, 121, 49, 51, 52, 35, 87, 107, 104, 112, 104, 35, 48, 52, 35, 87, 108, 112, 104, 35, 46, 52, 35, 70, 114, 48, 87, 107, 104, 112, 104, 35, 46, 53, 35, 40, 35, 108, 118, 35, 100, 111, 118, 114, 35, 94, 60, 48, 52, 57, 96, 13, 119, 108, 112, 104, 49, 113, 49, 51, 59, 35, 72, 84, 88, 35, 113, 114, 122, 35, 40, 35, 13, 115, 104, 117, 118, 114, 113, 49, 113, 49, 51, 52, 35, 85, 114, 111, 104, 35, 46, 52, 35, 40, 35, 100, 35, 105, 117, 108, 104, 113, 103, 35, 114, 105, 35, 94, 52, 58, 48, 53, 59, 96, 13, 105, 117, 108, 104, 113, 103, 49, 113, 49, 51, 52, 35, 82, 105, 35, 46, 52, 35, 40, 35, 13, 115, 104, 117, 118, 114, 113, 49, 113, 49, 51, 52, 35, 72, 84, 88, 35, 118, 115, 104, 100, 110, 104, 117, 35, 40, 35, 112, 108, 113, 104, 49, 35, 94, 53, 60, 48, 54, 55, 96, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxQupxiDCemH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}